{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115f1c98-9bde-4ed9-8458-f6f7d723aab8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Propositional Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aead8afc-84ee-4aca-8154-5f706022995c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the previous notebooks, we've demonstrated how logic can be used to reason about data using knowledge. We've also seen how LNNs extend truth value semantics to include uncertainties and ambiguities about beliefs. However, one of the key advantages of neural networks is their ability to learn from the data and update parameters to achieve some objective. In this notebook, we'll demonstrate how learnable parameters can be included into LNNs and allow for logical consistency to be enforced.\n",
    "\n",
    "### Learning Outcomes Of This Tutorial\n",
    "\n",
    "1. Learning To Be Consistent\n",
    "    1. Representing Inconsistencies\n",
    "    2. Parameterising The Operators\n",
    "    3. LNN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a85d4a-f76f-4184-bedc-e8c45cf1850c",
   "metadata": {},
   "source": [
    "## Learning To Be Consistent\n",
    "\n",
    "### Representing Inconsistencies\n",
    "\n",
    "The [Propositional Logic Notebook](./0.%20Propositional%20Logic.ipynb) demonstrates how LNNs represent knowledge using as graphical structure to perform reasoning. These structures encode knowledge in a manner that is consistent with existing theorem provers but extend them by allowing bounds to encode truth value semantics. One of the advantages of using this representation is that logical inconsistencies can be identified once reasoning has taken place.\n",
    "\n",
    "<center>\n",
    "    <figure>\n",
    "    <img src=\"./img/2/unweighted_representation.png\" width=\"320\" />\n",
    "        <figcaption>Figure 1. Graphical representation of an LNN</figcaption>\n",
    " </figure>\n",
    "</center>\n",
    "\n",
    "A [logical inconsistency](https://en.wikipedia.org/wiki/Consistency) is a belief that a node should both be _True_ and _False_ simultaneously, introducing a new state called a <strong style=color:#d02670>CONTRADICTION</strong>. In LNNs it occurs when an inference computation updates the correct truths to be outside a viable range. From the bounds representation, this occurs when the lower bound crosses over the upper bound and introduces an infeasible inequality for the correct truth value, $T$:\n",
    "\\begin{equation}L_x > U_x,  T_x > L_x, T_x < U_x\\end{equation}\n",
    "\n",
    "<center>\n",
    "    <figure>\n",
    "    <img src=\"./img/2/contradiction.png\" width=\"320\" />\n",
    "        <figcaption>Figure 2. Inconsistent inferences causes a contradiction</figcaption>\n",
    " </figure>\n",
    "</center>\n",
    "\n",
    "In a classical system, the bounds representation of a contradiction is therefore $[L, U] = [1, 0]$\n",
    "\n",
    "### Parameterising The Operators\n",
    "\n",
    "To allow for parameter learning, LNNs extend the operators to a weighted real-value logic that can be updated using gradient descent and backpropogation techniques. This is achieved by parameterising the edges of the graph such that each operand has a weighted influence on the truth of the operator, in line with current neural networks.\n",
    "\n",
    "<center>\n",
    "    <figure>\n",
    "    <img src=\"./img/2/weighted_representation.png\" width=\"320\" />\n",
    "        <figcaption>Figure 3. Weighted representation of an LNN graph</figcaption>\n",
    " </figure>\n",
    "</center>\n",
    "\n",
    "Each weighted [real-value logic](https://en.wikipedia.org/wiki/Fuzzy_logic) has a different definition of a logical operation (even for the same symbol), but we can implement them all by modifying the activation function. In LNNs we therefore use a graph representation whereby some of the nodes behave as neurons, i.e. for weighted logical connectives such as `And`, `Or`, `Implies`.\n",
    "\n",
    "### LNN Training\n",
    "\n",
    "In this section, we demonstrate how to train a single logical conjunction to become consistent when inconsistencies arise. \n",
    "\n",
    "If we are given a mix of _True_ and _False_ propositions in a logical conjunction that we expected to also be _True_:\n",
    "<center>\n",
    "    <figure>\n",
    "    <img src=\"./img/2/and_1.png\" width=\"520\" />\n",
    "        <figcaption>Figure 1. Logical conjunction between nodes</figcaption>\n",
    " </figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19a3be79-de61-4cd4-a1a5-09df7bb4d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lnn import Propositions, And, Fact\n",
    "\n",
    "# Rules\n",
    "A, B, C, D, E = Propositions(\"A\", \"B\", \"C\", \"D\", \"E\")\n",
    "AND = And(A, B, C, D, E)\n",
    "\n",
    "# Data\n",
    "A.add_data(Fact.TRUE)\n",
    "B.add_data(Fact.FALSE)\n",
    "C.add_data(Fact.TRUE)\n",
    "D.add_data(Fact.FALSE)\n",
    "E.add_data(Fact.TRUE)\n",
    "AND.add_data(Fact.TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6c8c09-6d84-4490-ae45-7aadfd493f07",
   "metadata": {},
   "source": [
    "We expect an upward inference at the conjunction will cause a contradiction:\n",
    "<center>\n",
    "    <figure>\n",
    "    <img src=\"./img/2/and_2.png\" width=\"520\" />\n",
    "        <figcaption>Figure 2. Upward inference causing a contradiction</figcaption>\n",
    " </figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc93dfc3-6a4e-4c5a-bfa6-432f92fa92c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPEN And: (A âˆ§ B âˆ§ C âˆ§ D âˆ§ E)                      CONTRADICTION (1.0, 0.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lnn import Model, Loss, Direction\n",
    "\n",
    "# Knowledge\n",
    "model = Model()\n",
    "model.add_knowledge(AND)\n",
    "\n",
    "# Reasoning\n",
    "model.infer()\n",
    "AND.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06780dcb-f1c5-4382-ad53-a1dd72a080ad",
   "metadata": {},
   "source": [
    "By introducing a loss on the contradiction:\n",
    "\n",
    "\\begin{align}\n",
    " Loss = \\lambda \\sum_{\\forall i} \\text{max} (0, L_i - U_i)\n",
    "\\end{align}\n",
    "\n",
    "we can train the LNN to adjust the weights such that all sources of contradictions (the _False_ inputs) become downweighted and eventually removed.\n",
    "\n",
    "<center>\n",
    "    <figure>\n",
    "    <img src=\"./img/2/and_3.png\" width=\"520\" />\n",
    "        <figcaption>Figure 3. Training the LNN using a contradiction loss</figcaption>\n",
    " </figure>\n",
    "</center>\n",
    "\n",
    "\n",
    "A final reasoning pass with the updated parameters causes the logical conjunction to remain <strong style=color:#0e6027>TRUE</strong> and keeps it consistent with the data that has been supplied. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06a38fc4-a89d-45c4-9628-2ccfe64c0973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPEN And: (A âˆ§ B âˆ§ C âˆ§ D âˆ§ E)                               TRUE (1.0, 1.0)\n",
      "params  Î±: 1.0,  Î²: 1.0,  w: [1. 0. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.train(direction=Direction.UPWARD, losses=[Loss.CONTRADICTION])\n",
    "AND.print(params=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7df6ba-62db-461f-91b0-2ece9d13aa42",
   "metadata": {},
   "source": [
    "As expected, the weights of the `False` inputs have all dropped to zero, removing their contribution to the truth of the `And` node. The resulting network therefore reasons in a self-supervised manner, ensuring that the interaction between the knowledge and the data is consistent.\n",
    "> When unspecified, the loss coefficient $\\lambda = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b87c44-4085-46b8-bb4d-b02db7191a72",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### In Summary\n",
    "\n",
    "In this notebook we learnt the following:\n",
    "- The bounds representation also allows for contradictions to be represented.\n",
    "- Contradictions occur at inference due to opposing truth updates.\n",
    "- LNNs extend the logical theory by allowing weights on real-value computations .\n",
    "- A loss can be introduced on inconsistencies for each node in the graph.\n",
    "- Inconsistent inputs can be downweighted to remove their influence on operator truths.\n",
    "\n",
    "Congrats on completing the Propositional Learning ðŸŽ‰. Next, we will learn about upward inference.\n",
    "> For those who have been taking the [IBM Neuro-Symbolic AI Essentials](https://ibm.biz/nsai-essentials) badge, proceed to the [propositional experiment](./experiments/experiment%200.ipynb) to test your skills."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
